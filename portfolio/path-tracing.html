<html>
	<head>
		<!-- <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script> -->
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 10%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
			td {
				padding: 10px;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>Path Tracing</h1>
		<h1 style="font-size: 20px;">CS184/284A Spring 2025</h1>
		<div style="text-align: center;">By <a href="https://github.com/nekolocation" target=”_blank”>Edward Gilmore</a> and <a href="https://github.com/jovinV" target=”_blank”>Jovin Valdez</a> </div>

		<br>

		
		<figure>
			<img src="assets\img\pathtrace\example_image.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>the bun is in the... uh... hmm...</figcaption>
		</figure>

		<h2>Overview</h2>
		<p>We implemented a path tracer that simulates realistic lighting. First we applied the Möller Trumbore Algorithm using barycentric coordinates to be able to check whether a ray collides with a triangle or sphere. We then were able to build a bounding volume hierarchy by using recursion to construct bounding boxes around primitives, using those boxes to construct larger, parent bounding boxes. With this BVH algorithm, rendering time was significantly decreased. To simulate direct lighting we implemented sampling methods that aggregate lighting contributions, such as uniform hemisphere sampling which samples directions uniformly from a hemisphere above a hitpoint, and also importance lighting sampling where we loop through every lightsource in a scene and sample the directions towards each light. We accomplished indirect lighting by applying similar ideas except now considering the light bouncing off of surfaces, using Russian Roulette rendering to randomly terminate rays early. Finally, we implemented adaptive sampling to focus on more difficult noisy parts of a rendering and avoid pixels that have already merged. It was very interesting to learn the algorithms and applications of real lighting physics to simulate 3D scenes. It was also cool to see how drastically the mood of a rendered piece can change depending on the amount of noise in the rendered image, and whether it’s illuminated by direct lighting or just indirect lighting.</p>

		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		<p>The image rendering pipeline involves generating rays and casting them to find their intersection with objects. The rays are generated by first transforming normalized image coordinates into camera space, then by transforming the rays into world space. We estimate the integral of radiance over a given pixel and average it, providing this value to the sample buffer.</p>
		<p>To calculate the intersection of a given ray and a triangle, we find any points of intersection by implementing the Möller Trumbore Algorithm (explained further below). This helps us determine the ray’s nearest point of intersection with a triangle. We then adjust our bounds for the ray’s maximum intersection to ignore any intersections past this point, since the collision of the ray with the object should stop it from moving in that direction.</p>
		<p>The Möller Trumbore Algorithm tests the intersection of rays by utilizing Barycentric coordinates; by finding the barycentric values correlated to the three vertices of the triangle, we can check whether the triangle passes through the triangle (if the values for b1, b2, and b3 all lie between 0 and 1 inclusive).  To calculate the barycentric coefficients, first we find the vectors for the triangle’s edges and the ray origin, then use these vectors with the vector of the ray’s direction to find the determinant vectors. The determinate vectors tell us the orientation of the triangle relative to the ray, and where in the triangle the ray lands. We can then use these values in dot product calculations to find the barycentric coordinates of the intersection. We then update an Intersection object with data about the results of this calculation.</p>
		<p>For collision with spheres, instead of using barycentric calculations we solve a quadratic equation, based on the origin and direction of the ray, as well as the origin and radius of the sphere. </p>
		<p>This allows us to render .dae files like the following:</p>

		<!-- <p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p> -->
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part1_CBspheres.png" width="400px"/>
				  <figcaption>orb.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part1_Bunny.png" width="400px"/>
				  <figcaption>bnuny</figcaption>
				</td>
			  </tr>
			  <!-- <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\example_image.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\example_image.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr> -->
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		<p>In building our bounding volume hierarchy,we recursively build bounding boxes around primitives and add these boxes together to create larger, parent bounding boxes. If our node holds primitives less than a variable size, it’s considered a leaf node. Otherwise, left and right subtrees are created along the axis that splits the primitives most evenly. We accomplish our split by finding our longest axis and sort our primitives based on the centroid of the bounding boxes. </p>
		<p>As a result, we can render much more complicated .dae files:</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part2_beast.png" width="400px"/>
				  <figcaption></figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part2_cblucy.png" width="400px"/>
				  <figcaption></figcaption>
				</td>
			  </tr>
			  <!-- <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\example_image.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\example_image.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr> -->
			</table>
		</div>

		<p>Implementing a bounding volume hierarchy significantly sped up our render times. Across different scenes with complex mesh geometries, the implementation sped up the total rendering time by a factor of 100 (382.9 seconds without BVH implementation, 0.2233 seconds with BVH implementation). As a trade off, the construction of the bounding boxes took 100 times longer, but since this time was a fraction of a second to begin with (0.0015 seconds without BVH implementation, 0.1433 seconds with BVH implementation), this work pays off tremendously. As well, intersection tests per ray are much lower with BVH (averaging 33,696 without BVH and merely 4.02 with BVH).</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part2_time-before.png" width="520px"/>
				  <figcaption>Before</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part2_time-after.png" width="520px"/>
				  <figcaption>After</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h2>Part 3: Direct Illumination</h2>
		<p>In implementing uniform hemisphere sampling, we sample multiple directions uniformly from the hemisphere above the surface. We take a single sample by converting that direction to world coordinates and casting a shadow ray from the hit point in the sample direction. If that shadow ray hits a light source, our incoming radiance is that light source’s emission. Using the BSDF, cosine of angle between incoming direction and surface normal, and PDF, we can then use the reflection equation to calculate the light contribution of this sample. We finally then average the aggregate of these contributions to approximate the direct lighting.</p>
		<p>For the importance sampling implementation we do a lot of the same things like adding up light contributions from samples, but this time we loop through every light source in the scene, and sample the direction towards each light using sample_L. We still cast a shadow ray from the hit point to the light, and if it’s not blocked by a surface then we compute the night contribution using the same equation as before and average over multiple samples for area lights using only 1 sample for point lights.</p>
		<p>Below, we can see the outputs rendered by the two different sampling methods:</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part3_uniform_hemisphere.png" width="400px"/>
				  <figcaption>Uniform Hemisphere Sampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part3_importance_lighting.png" width="400px"/>
				  <figcaption> Importance Lighting Sampling</figcaption>
				</td>
			  </tr>
			  <!-- <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\example_image.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\example_image.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr> -->
			</table>
		</div>

		<p>Here, we render a scene repeatedly with an increasing amount of light rays. Notice that as the amount of rays increases, the amount of noise decreases and the shadows become softer, starting at 1 light ray (noisiest, roughest shadows) and moving to 64 light rays (least noise, smoothest shadows).</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part3_dragon_importance_1.png" width="400px"/>
				  <figcaption>1 Light Ray</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="assets\img\pathtrace\part3_dragon_importance_4.png" width="400px"/>
					<figcaption>4 Light Rays</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
					<img src="assets\img\pathtrace\part3_dragon_importance_16.png" width="400px"/>
					<figcaption>16 Light Rays</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="assets\img\pathtrace\part3_dragon_importance_64.png" width="400px"/>
					<figcaption>64 Light Rays</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>With the lighting sampling, the images had significantly less noise and had smoother shadows compared to uniform hemisphere sampling. The uniform hemisphere sampling renderings are noticeably more grainy looking, especially at lower light sample counts.</p>

		<h2>Part 4: Global Illumination</h2>
		<p>Our implementation steps begin similarly to the previous part: we make a local coordinate system, calculate the hit point, and convert the outgoing direction to local space. We then recursively evaluate ray bouncing according to parameters (namely the max_ray_depth variable which establishes our base case). We sample using an Intersection object which uses importance sampling, tracing a new ray to apply indirect radiance. Even with the bounding volume hierarchy this process can still take quite long, so we also added Monte Carlo sampling using russian roulette to probabilistically terminate the path. Depending on whether bounce accumulation is enabled, we either add both direct and indirect light contributions or just return the indirect one.</p>
		<p>The combined direct and indirect lighting implementations allow rendered images to bounce light rays and simulate ambient colored lighting, demonstrated below:</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_gdi_CBbunny.png" width="400px"/>
				  <figcaption>Bunny all lit up</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_gdi_CBspheres_lambertian.png" width="400px"/>
				  <figcaption><em>orb.</em></figcaption>
				</td>
			  </tr>
			  <!-- <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\example_image.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\example_image.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr> -->
			</table>
		</div>

		<p>Below, the direct and indirect lighting have been isolated to demonstrate their effects:</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_bunny_direct.png" width="400px"/>
				  <figcaption>Only Direct Lighting</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="assets\img\pathtrace\part4/part4_bunny_indirect.png" width="400px"/>
					<figcaption>Only Indirect Lighting</figcaption>
				</td>
			  </tr>
			  <!-- <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\example_image.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\example_image.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr> -->
			</table>
		</div>

		<p>As seen above, direct lighting provides a rendering with clear illumination of surfaces such as the bunny and room walls since the light source can directly reach those surfaces, but it isn’t perfect since it doesn't account for any light that bounces off any other surfaces than the original hit point. Indirect illumination, on the other hand, is composed of light that has bounced off a surface first (in other words, all light that is not direct from the source to a given surface). In this rendering, the shadows and blending of colors look nicer, and more representative of the real world. However, this indirect lighting appears dark since we don’t show any of the direct light from the ceiling light.</p>

		<p>Below, we see a scene rendered with different max_ray_length values (m0 through m5) and with the light representing either the accumulated value of bounces or the accumulated value (ie: where light rays contribute only the value of only the final bounce that occurred).</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<b>No Accumulated Bounce</b>
					</td>
					<td style="text-align: center;">
						<b>With Accumulated Bounce</b>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m0-abf.png" width="400px"/>
						<figcaption>Noncumulative — m0</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m0-abt.png" width="400px"/>
						<figcaption>Accumulative — m0</figcaption>
					</td>
			  	</tr>
				<tr>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m1-abf.png" width="400px"/>
						<figcaption>Noncumulative — m1</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m1-abt.png" width="400px"/>
						<figcaption>Accumulative — m1</figcaption>
					</td>
			  	</tr>
				<tr>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m2-abf.png" width="400px"/>
						<figcaption>Noncumulative — m2</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m2-abt.png" width="400px"/>
						<figcaption>Accumulative — m2</figcaption>
					</td>
			  	</tr>
				<tr>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m3-abf.png" width="400px"/>
						<figcaption>Noncumulative — m3</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m3-abt.png" width="400px"/>
						<figcaption>Accumulative — m3</figcaption>
					</td>
			  	</tr>
				<tr>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m4-abf.png" width="400px"/>
						<figcaption>Noncumulative — m4</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m4-abt.png" width="400px"/>
						<figcaption>Accumulative — m4</figcaption>
					</td>
			  	</tr>
				<tr>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m5-abf.png" width="400px"/>
						<figcaption>Noncumulative — m5</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="assets\img\pathtrace\part4/part4_m5-abt.png" width="400px"/>
						<figcaption>Accumulative — m5</figcaption>
					</td>
			  	</tr>
			</table>
		</div>

		<p>With non-accumulated lighting we can only see the light at a given position when it collides with a surface; a noticeable effect of this is that we can only see the ceiling light at depth 0, since the light has not yet moved from its source at that time. For both accumulated and non-accumulated renders, depth 1 shows the direct lighting of the scene. At depth 2, the light is bounced around the room, reaching places that only direct illumination wouldn’t reach (notably the ceiling). As a result, the scene generally becomes lighter (particularly affecting parts of the scene that were darkest)– though in the non-accumulated bounce renders, the brightest parts of the scene become darker as a tradeoff. Along these lines, the renders with more than one bounce have indirect lighting, and thus more color blending and detailed shading. However, from m2 onwards the noncumulative bounce renders are overall darker, since light loses energy after bouncing off a surface. The darker appearance is even more apparent at depth 3, due to the light losing even more energy the more it bounces. With a path tracing approach we can more accurately simulate light by mimicking physical phenomena, producing better results when compared to traditional rasterization. Path tracing results in better quality renderings due to more accurate color blending and soft shadows.</p>

		<p>With accumulated lighting, we can always see the ceiling light at all depths. As we increase the depth, we see more color blending and an overall more lit rendering since we are accumulating the light for every depth. At depth 2 the lighting and shading look pretty realistic, and at depth 3 there appears to be more ambient color lighting in the shadows (although it is very subtle and hard to notice unless looked at very carefully). Beyond this, however, it is pretty hard to see the differences as we increase depth.</p>

		<p>Below, we demonstrate our implementation of Russian Roulette rendering, which uses early termination on rays with a random probability of 30%. At low max_ray_depth values, this has a noticeably negative effect on the image quality– at m0, the light source is seen missing several pixels, because not all the rays have a chance to provide proper light info for those scene pixels. Conversely, using roulette allows us to render images with much higher max_ray_depth values, such as the m100 render seen below.</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_roulette_m0.png" width="400px"/>
				  <figcaption>Roulette sampling — m0</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_roulette_m1.png" width="400px"/>
				  <figcaption>Roulette sampling — m1</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_roulette_m2.png" width="400px"/>
				  <figcaption>Roulette sampling — m2</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_roulette_m3.png" width="400px"/>
				  <figcaption>Roulette sampling — m3</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_roulette_m4.png" width="400px"/>
				  <figcaption>Roulette sampling — m4</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_roulette_m100.png" width="400px"/>
				  <figcaption>Roulette sampling — m100</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Below we demonstrate a .dae file rendered repeatedly at different sample-per-pixel rates. With lower sample-per-pixel rates, we can see how the renderings are considerably more grainy. As we go up from 1 to 2 to 4 and so on, at these low levels we can still noticeably see the noise, but at much higher rates such as 1024 the rendering is very smooth with no significant graininess at all.</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_spp1.png" width="400px"/>
				  <figcaption>1 Sample-per-pixel</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_spp2.png" width="400px"/>
				  <figcaption>2 Samples-per-pixel</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_spp4.png" width="400px"/>
				  <figcaption>4 Samples-per-pixel</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_spp8.png" width="400px"/>
				  <figcaption>8 Samples-per-pixel</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_spp16.png" width="400px"/>
				  <figcaption>16 Samples-per-pixel</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_spp64.png" width="400px"/>
				  <figcaption>64 Samples-per-pixel</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part4/part4_spp1024.png" width="400px"/>
				  <figcaption>1024 Samples-per-pixel</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h2>Part 5: Adaptive Sampling</h2>
		<p>Adaptive sampling works by concentrating samples in more difficult parts of a rendering, avoiding using too many samples per pixel. We implemented it by checking the convergence of each pixel’s radiance estimate as the samples are accumulated. We loop over a max number of samples per pixel, and after every samplesPerBatch we calculate some statistics such as the mean and variance of the illuminance to compute a confidence interval and compare it to maxTolerance. If the confidence interval is small though, meaning the additional samples won’t significantly change the estimated radiance, we stop sampling for that pixel. This way, we focus more on noisy regions and avoid pixels that have already converged.</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="assets\img\pathtrace\part5_blob.png" width="400px"/>
				  <figcaption></figcaption>
				</td>
				<td style="text-align: center;">
					<img src="assets\img\pathtrace\part5_blob_rate.png" width="400px"/>
					<figcaption></figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
					<img src="assets\img\pathtrace\part5_wall-e.png" width="400px"/>
					<figcaption></figcaption>
				  </td>
				  <td style="text-align: center;">
					  <img src="assets\img\pathtrace\part5_wall-e_rate.png" width="400px"/>
					  <figcaption></figcaption>
				  </td>
			  </tr>
			</table>
		</div>

		<!-- <h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul> -->
		</div>
	</body>
</html>